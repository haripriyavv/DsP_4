# -*- coding: utf-8 -*-
"""appipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mc9YX4EUFS8ST0LG79j8fjm9P-G_s3fd
"""

import sklearn
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
import seaborn as sns
import matplotlib.pyplot as plt

# --- Load data ---

@st.cache_data
def load_data():
    import pandas as pd
    books = pd.read_csv("Books(2).gz", compression='gzip', on_bad_lines='skip', low_memory=False)
    users = pd.read_csv("Users (2).csv", on_bad_lines='skip')
    ratings = pd.read_csv("Ratings (1).csv", on_bad_lines='skip')

    users['Age'] = pd.to_numeric(users['Age'], errors='coerce')
    users = users[(users['Age'] >= 5) & (users['Age'] <= 100)]
    ratings = ratings[ratings['Book-Rating'] > 0]

    return books, users, ratings

books, users, ratings = load_data()

# --- Filter active users and popular books ---
active_users = ratings['User-ID'].value_counts()[ratings['User-ID'].value_counts() > 10].index
popular_books = ratings['ISBN'].value_counts()[ratings['ISBN'].value_counts() > 20].index
filtered_ratings = ratings[(ratings['User-ID'].isin(active_users)) & (ratings['ISBN'].isin(popular_books))]

# --- Create user-item pivot table ---
pivot = filtered_ratings.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)

# --- Train KNN model ---
model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(pivot.values)

# --- Recommendation function ---
def recommend_books(user_id, n=5):
    if user_id not in pivot.index:
        return None

    user_vector = pivot.loc[user_id].values.reshape(1, -1)
    distances, indices = model_knn.kneighbors(user_vector, n_neighbors=n + 1)
    similar_users = pivot.index[indices.flatten()[1:]]

    weights = 1 - distances.flatten()[1:]
    weights = np.where(weights == 0, 1e-6, weights)

    similar_ratings = pivot.loc[similar_users]
    weighted_ratings = (similar_ratings.T * weights).T
    avg_ratings = weighted_ratings.sum() / weights.sum()
    avg_ratings = avg_ratings.sort_values(ascending=False)

    already_rated = pivot.loc[user_id]
    recommendations = avg_ratings[already_rated == 0].head(n)

    rec_books = books[books['ISBN'].isin(recommendations.index)][['Book-Title', 'Book-Author']].drop_duplicates()
    return rec_books.reset_index(drop=True)

# --- Streamlit UI ---

st.title("ðŸ“š Book Recommendation System")

st.sidebar.header("User Input")
user_id = st.sidebar.number_input("Enter User ID", min_value=int(pivot.index.min()), max_value=int(pivot.index.max()), value=int(pivot.index.min()))

num_recs = st.sidebar.slider("Number of Recommendations", 1, 10, 5)

if st.sidebar.button("Get Recommendations"):
    recommendations = recommend_books(user_id, n=num_recs)
    if recommendations is None or recommendations.empty:
        st.write("No recommendations found for this user. Try a different User ID.")
    else:
        st.subheader(f"Top {num_recs} Recommendations for User {user_id}")
        for i, row in recommendations.iterrows():
            st.write(f"**{i+1}. {row['Book-Title']}** by *{row['Book-Author']}*")

# --- Optional: Show some plots ---

if st.checkbox("Show Data Insights"):
    st.subheader("Top 10 Most Rated Books")
    top_books = ratings['ISBN'].value_counts().head(10).reset_index()
    top_books.columns = ['ISBN', 'RatingCount']
    top_books = top_books.merge(books[['ISBN', 'Book-Title']], on='ISBN', how='inner')
    st.bar_chart(top_books.set_index('Book-Title')['RatingCount'])

    st.subheader("Distribution of Ratings")
    st.bar_chart(ratings['Book-Rating'].value_counts().sort_index())

    st.subheader("User Age Distribution")
    st.bar_chart(users['Age'].dropna())
