# -*- coding: utf-8 -*-
"""P3.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ePPf9C7WhbTchyKjOPtyZ390Gt_Axzdf
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors

books = pd.read_csv("Books (2).csv", on_bad_lines='skip', low_memory=False)
users = pd.read_csv("Users (2).csv", on_bad_lines='skip')
ratings = pd.read_csv("Ratings (1).csv", on_bad_lines='skip')

users['Age'] = pd.to_numeric(users['Age'], errors='coerce')
users = users[(users['Age'] >= 5) & (users['Age'] <= 100)]

ratings = ratings[ratings['Book-Rating'] > 0]

top_books = ratings['ISBN'].value_counts().head(10).reset_index()
top_books.columns = ['ISBN', 'RatingCount']
top_books = top_books.merge(books[['ISBN', 'Book-Title']], on='ISBN', how='inner')

plt.figure(figsize=(12, 6))
sns.barplot(x=top_books['Book-Title'], y=top_books['RatingCount'], palette='viridis')
plt.xticks(rotation=90)
plt.title("Top 10 Most Rated Books")
plt.xlabel("Book Title")
plt.ylabel("Number of Ratings")
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(ratings['Book-Rating'], bins=10, kde=True, color='skyblue')
plt.title("Distribution of Ratings")
plt.xlabel("Rating")
plt.ylabel("Frequency")
plt.show()


plt.figure(figsize=(8, 5))
sns.histplot(users['Age'], bins=20, kde=True, color='salmon')
plt.title("Distribution of User Ages")
plt.xlabel("Age")
plt.ylabel("Number of Users")
plt.tight_layout()
plt.show()

book_author_rating_counts = ratings.merge(books[['ISBN', 'Book-Author']], on='ISBN', how='inner')
top_authors = book_author_rating_counts['Book-Author'].value_counts().head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x=top_authors.values, y=top_authors.index)
plt.title("Top 10 Most Rated Authors")
plt.xlabel("Number of Ratings")
plt.ylabel("Author")
plt.tight_layout()
plt.show()
users['Country'] = users['Location'].apply(lambda x: x.split(',')[-1].strip() if isinstance(x, str) and ',' in x else 'Unknown')
top_countries = users['Country'].value_counts().head(10)

plt.figure(figsize=(10, 5))
sns.barplot(x=top_countries.values, y=top_countries.index)
plt.title("Top 10 Countries by Number of Users")
plt.xlabel("Number of Users")
plt.ylabel("Country")
plt.tight_layout()
plt.show()

active_users = ratings['User-ID'].value_counts()[ratings['User-ID'].value_counts() > 10].index
popular_books = ratings['ISBN'].value_counts()[ratings['ISBN'].value_counts() > 20].index
filtered_ratings = ratings[(ratings['User-ID'].isin(active_users)) & (ratings['ISBN'].isin(popular_books))]

pivot = filtered_ratings.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)

model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(pivot.values)


def recommend_books(user_id, n=5):
    if user_id not in pivot.index:
        return " User ID not found or not active enough."

    try:
        user_vector = pivot.loc[user_id].values.reshape(1, -1)
        distances, indices = model_knn.kneighbors(user_vector, n_neighbors=n + 1)
        similar_users = pivot.index[indices.flatten()[1:]]

        weights = 1 - distances.flatten()[1:]
        weights = np.where(weights == 0, 1e-6, weights)

        similar_ratings = pivot.loc[similar_users]
        weighted_ratings = (similar_ratings.T * weights).T
        avg_ratings = weighted_ratings.sum() / weights.sum()
        avg_ratings = avg_ratings.sort_values(ascending=False)

        already_rated = pivot.loc[user_id]
        recommendations = avg_ratings[already_rated == 0].head(n)

        rec_books = books[books['ISBN'].isin(recommendations.index)][['Book-Title', 'Book-Author']].drop_duplicates()
        rec_books = rec_books.reset_index(drop=True)

        if rec_books.empty:
            return " No new recommendations found. Try increasing `n` or using a different user."

        print("\n Top Recommended Books:")
        for idx, row in rec_books.iterrows():
            print(f"{idx+1}. {row['Book-Title']} by {row['Book-Author']}")
        return rec_books

    except Exception as e:
        return f"‚ùå Error generating recommendations: {str(e)}"

print(" Sample Active User IDs (use one of these below):")
print(filtered_ratings['User-ID'].value_counts().head(10).index.tolist())

print("\n Testing with user_id=11676")
recommend_books(user_id=11676, n=5)
item_pivot = filtered_ratings.pivot_table(index='ISBN', columns='User-ID', values='Book-Rating').fillna(0)

model_item_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_item_knn.fit(item_pivot.values)

def recommend_similar_books(isbn, n=5):
    if isbn not in item_pivot.index:
        return "ISBN not found in filtered data."

    distances, indices = model_item_knn.kneighbors(item_pivot.loc[isbn].values.reshape(1, -1), n_neighbors=n+1)
    similar_isbns = item_pivot.index[indices.flatten()[1:]]

    return books[books['ISBN'].isin(similar_isbns)][['Book-Title', 'Book-Author']].drop_duplicates().reset_index(drop=True)

from surprise.model_selection import cross_validate
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate
import pandas as pd

sampled_ratings = ratings.sample(n=10000, random_state=42)

reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(sampled_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)

model = SVD()
results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)
print(results)
print("Average RMSE:", results['test_rmse'].mean())
print("Average MAE:", results['test_mae'].mean())

from surprise import KNNBasic, BaselineOnly

models = {
    "SVD": SVD(),
    "KNNBasic": KNNBasic(),
    "BaselineOnly": BaselineOnly()
}

for name, model in models.items():
    print(f"\nEvaluating {name}")
    results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)
    print(f"Average RMSE: {results['test_rmse'].mean():.4f}")
    print(f"Average MAE: {results['test_mae'].mean():.4f}")

trainset = data.build_full_trainset()
best_model.fit(trainset)

uid = '11676'
iid = '0385504209'
pred = best_model.predict(uid, iid)
print(f"Predicted rating of user {uid} for book {iid}: {pred.est:.2f}")

def get_top_n_recommendations(model, user_id, books, ratings, n=5):
    user_rated_books = ratings[ratings['User-ID'] == user_id]['ISBN'].tolist()
    all_books = books['ISBN'].tolist()
    books_to_predict = [book for book in all_books if book not in user_rated_books]

    predictions = []
    for book in books_to_predict:
        pred = model.predict(user_id, book)
        predictions.append((book, pred.est))

    predictions.sort(key=lambda x: x[1], reverse=True)
    top_n = predictions[:n]

    rec_df = books[books['ISBN'].isin([isbn for isbn, _ in top_n])][['Book-Title', 'Book-Author']].copy()
    rec_df['Predicted Rating'] = [score for _, score in top_n]
    return rec_df.reset_index(drop=True)

print(get_top_n_recommendations(best_model, '11676', books, ratings, n=5))





